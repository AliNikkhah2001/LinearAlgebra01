{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOpA9df3Hmye"
      },
      "source": [
        "<h1 align=\"center\">Mathematical Methods in Engineering - Course Code: 25872</h1>\n",
        "<h4 align=\"center\">Instructor: Dr. Amiri</h4>\n",
        "<h4 align=\"center\">Sharif University of Technology, Spring 2023</h4>\n",
        "<h4 align=\"center\">Computer Assignment 3</h4>\n",
        "<h4 align=\"center\">\n",
        "\n",
        "Questions 1 & 2: [Zahra maleki](https://t.me/Rosebaekfany), Questions 3: [Radin Khayyam](https://t.me/Radinkhayyam)\n",
        "\n",
        "</h4>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VI9fqo7GHmy1"
      },
      "source": [
        "<p>\n",
        "    Write your code in the <span style=\"color: green;\">Code Cell</span> and run the <span style=\"color: green;\">Evaluation Cell</span> to check the output.<br>\n",
        "    <span style=\"color: red; font-weight: bold;\">Please refrain from editing the existing codes.</span>\n",
        "</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u9DkTK-NHmy1"
      },
      "outputs": [],
      "source": [
        "Name = \"\"\n",
        "Student_Number = \"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEVj8eSlHmy3"
      },
      "source": [
        "### Importing necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kan6lTbSHmy3"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import linalg\n",
        "from PIL import Image\n",
        "import time\n",
        "from numpy import asarray\n",
        "from sklearn.utils.extmath import randomized_svd\n",
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5JxFur9FHmy3"
      },
      "outputs": [],
      "source": [
        "np.random.RandomState(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GtYm7SHHmy3"
      },
      "source": [
        "## Problem 1: SVD for Compression ``(35 pt.)``\n",
        "\n",
        "In this question, we want to compress BMP images using SVD. BMP images are not compressed by default and the pixel information is stored in rather a simple format. Colored BMP files are composed of three matrices of size $n × m$ where $n$ and $m$ are the height and width of the image, respectively. Each matrix corresponds to one of the three colors Red, Green, and Blue. Each entry of these matrices is a number between 0 and 255 that specifies the intensity of the corresponding color. The final array is hence a 3D array of size $n × m × 3$.\n",
        "\n",
        "### 1.1 Image display\n",
        "Choose two arbitrary BMP files (it is recommended to use different subjects and sizes) and load it into a `numpy` array using the `imread` function. Then, show each image and display their shape."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nU5c7N7yHmy4"
      },
      "outputs": [],
      "source": [
        "# Code cell\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cY06PZtHmy4"
      },
      "source": [
        "### 1.2 Singular Value Decomposition and channel seperation\n",
        "\n",
        "Calculate the SVD decomposition of each of ech RGB channel.\n",
        "\n",
        "$$\n",
        "A = U \\Sigma V^T\n",
        "$$\n",
        "where $A$ is the original array, $U$ is an $n × n$ unitary matrix, $\\Sigma$ is an $n × m$ rectangular diagonal matrix with non-negative real numbers on the diagonal, and $V$ is an $m × m$ unitary matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6WfvV4H7Hmy4"
      },
      "outputs": [],
      "source": [
        "# Code cell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNkDr-25Hmy5"
      },
      "source": [
        "### 1.3 compressing the image\n",
        "\n",
        "Since eigenvalues in the decomposition are sorted in descending order, we can approximate the original array by keeping only the first $k$ columns of $U$, first $k$ rows and columns of $\\Sigma$, and first $k$ rows of $V^T$.\n",
        "Select $k$ to be (5, 10, 20, 30, 50, 100, 200, 250) and approximate the original array using the truncated SVD. Show the approximated image titled with the value of $k$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rnhCh0K7Hmy5"
      },
      "outputs": [],
      "source": [
        "# Code cell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgApkeTpHmy5"
      },
      "source": [
        "#### explion your results.\n",
        "\n",
        "Explain the relationship between the number of components and the level of compression in the images. How does the image quality change with increasing values of k?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MQfiWD9Hmy5"
      },
      "source": [
        "### 1.4 variance\n",
        "\n",
        "there is no need to store $U$ and $V$ matrices. Instead, we can store $\\Sigma$ and two other matrices of size $n × k$ and $m × k$. Using $\\Sigma$ display the plots below. To not compress the image based on a given random number k, we are required to do some math & statistics\n",
        "\n",
        "1. The plot \"Component Importance\" shows the  amount  of variance each component carries. The first component preserves the highest variance, then the second, and so on.\n",
        "2. The plot shows the explained variance as a function of numbers, using this technique you can choose how much the image, relative to its original size gets compressed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yEcwy2gBHmy5"
      },
      "outputs": [],
      "source": [
        "# Code cell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHkhlpOiHmy6"
      },
      "source": [
        "Compress the image with 90% of its explained variance ratio and show the result image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qAQGhVKgHmy6"
      },
      "outputs": [],
      "source": [
        "# Code cell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-NaeBsxHmy6"
      },
      "source": [
        "## Problem 2 ``(30 pt.)``\n",
        "\n",
        "### 2.1 Truncate the SVD\n",
        "Write the function of truncated_svd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fuQ8-aBIHmy6"
      },
      "outputs": [],
      "source": [
        "# Code cell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1t23ezcHmy6"
      },
      "source": [
        "### 2.2 Randomized SVD\n",
        "\n",
        "In the following cell, you should implement the randomized SVD for the input matrix. The number of empty lines below suggests the number of lines needed for a possible solution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7wI815OIHmy7"
      },
      "outputs": [],
      "source": [
        "def sqr(A):\n",
        "    Q, R = linalg.qr(A,mode=\"economic\")\n",
        "    return Q, R"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F28K3ZvyHmy7"
      },
      "outputs": [],
      "source": [
        "# This function performs randomized svd using linalg from scipy\n",
        "def rsvd(A, n_components, random_state, n_oversamples, n_iter):\n",
        "  # Sample column space of X with P matrix\n",
        "  ny = A.shape[1]\n",
        "  # TODO: set the random state of numpy\n",
        "  ######### your code here #########\n",
        "\n",
        "  ##################################\n",
        "  # TODO: Generate a random matrix P of shape (ny,n_components+n_oversamples)\n",
        "  ######### your code here #########\n",
        "  P = None\n",
        "  ##################################\n",
        "  Z = A @ P\n",
        "  # TODO: for n_iter iterations, computes A multiplied by A transpose multiplied by Z\n",
        "  ######### your code here #########\n",
        "\n",
        "\n",
        "  ##################################\n",
        "  Q,R = sqr(Z)\n",
        "  # Step 2: Compute SVD on projected Y = Q.T @ X, name them U1,S,VT\n",
        "  ######### your code here #########\n",
        "\n",
        "\n",
        "  ##################################\n",
        "  U = Q @ U1\n",
        "\n",
        "  return U[:, :n_components], S[:n_components], VT[:n_components, :]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9lrEW_dHmy7"
      },
      "source": [
        "In the following cell, implement the rsvd as you did before but this time use the LU decomposition instead of the multiplication of matrices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lx2JW0KOHmy7"
      },
      "outputs": [],
      "source": [
        "# Using lu insted of multiplication (can be quite unstable try different random seeds if needed)\n",
        "def nrsvd(A, n_components, random_state, n_oversamples, n_iter):\n",
        "  ######### your code here #########\n",
        "\n",
        "  ##################################\n",
        "  return U[:, :n_components], S[:n_components], VT[:n_components, :]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lJooFR7Hmy7"
      },
      "source": [
        "This function performs the randomized SVD of sklearn library. Do not change this cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVps59RAHmy7"
      },
      "outputs": [],
      "source": [
        "def srsvd(A, n_components, random_state, n_oversamples, n_iter):\n",
        "  U, s, Vh = randomized_svd(A, n_components=n_components, random_state=random_state, n_oversamples=n_oversamples, n_iter=n_iter)\n",
        "  return U[:, :n_components], s[:n_components], Vh[:n_components, :]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlIQy64wHmy8"
      },
      "source": [
        "In order to test your randomized SVD code, please run the following cell. It contains test cases to verify the correctness of your implementation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49DhEhiAHmy8"
      },
      "outputs": [],
      "source": [
        "def make_matrix(m,n,k,randomstate):\n",
        "    n_rows = m\n",
        "    n_cols = n\n",
        "    t = int(n_rows*n_cols*k)\n",
        "    np.random.RandomState(randomstate)\n",
        "    rr = np.random.choice(np.arange(0,n_rows),t)\n",
        "    cr = np.random.choice(np.arange(0,n_cols),t)\n",
        "    M = np.zeros((n_rows,n_cols))\n",
        "    M[rr,cr]= 1\n",
        "    return M\n",
        "\n",
        "def base_rsvd(rsvdscipy,att):\n",
        "  err = [0]*len(att)\n",
        "  tim = [0]*len(att)\n",
        "  for i in range(len(att)):\n",
        "    M = make_matrix(att[i][0],att[i][1],0.01,att[i][3])\n",
        "    start_time = time.time()\n",
        "    U, s, Vh = rsvdscipy(M,att[i][2],att[i][3],att[i][4],att[i][5])\n",
        "    time_length = time.time() - start_time\n",
        "    M_rec = U @ np.diag(s) @ Vh\n",
        "    error = np.linalg.norm(M - M_rec, ord='fro')/np.linalg.norm(M, ord='fro')\n",
        "    err[i] = error\n",
        "    tim[i] = time_length\n",
        "    print(f\"srsvd test {i+1}: error: {error:.3f}, time: {time_length:.3f}\")\n",
        "  print(\"-------------------------------\")\n",
        "  return err,tim\n",
        "\n",
        "def test_rsvd(rsvdscipy,svd1):\n",
        "  att = [(3000,3000,500,0,10,4),(1500,1400,500,0,10,5),(2000,5000,400,0,10,7),(6000,2600,400,0,10,3)]\n",
        "  err,tim = base_rsvd(rsvdscipy,att)\n",
        "  for i in range(4):\n",
        "    M = make_matrix(att[i][0],att[i][1],0.01,att[i][3])\n",
        "    start_time = time.time()\n",
        "    U, s, Vh = svd1(M,att[i][2],att[i][3],att[i][4],att[i][5])\n",
        "    time_length = time.time() - start_time\n",
        "    M_rec = U @ np.diag(s) @ Vh\n",
        "    error = np.linalg.norm(M - M_rec, ord='fro')/np.linalg.norm(M, ord='fro')\n",
        "    if error > err[i]+0.1:\n",
        "      print(f\"Test{i+1}, Alg rsvd: \\033[31mFailed!\\033[0m because of error \\n with Error {error:.3f} and time {time_length:.3f} \\n ------------------\")\n",
        "    elif time_length > tim[i]+0.5:\n",
        "      print(f\"Test{i+1}, Alg rsvd: \\033[31mFailed!\\033[0m because of time \\n with Error {error:.3f} and time {time_length:.3f} \\n ------------------\")\n",
        "    else:\n",
        "      print(f\"Test{i+1}, Alg rsvd: \\033[32mPassed!\\033[0m \\n with Error {error:.3f} and time {time_length:.3f} \\n ------------------\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hXV_U3l6Hmy8"
      },
      "outputs": [],
      "source": [
        "test_rsvd(srsvd,rsvd)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8zLpXJaHmy8"
      },
      "source": [
        "Here you can visualize the result of various svd methods on a cat image. You can also compare the time it takes for each method to run."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NGV1I1PjHmy8"
      },
      "outputs": [],
      "source": [
        "url = 'https://images.pexels.com/photos/45201/kitty-cat-kitten-pet-45201.jpeg?cs=srgb&dl=pexels-pixabay-45201.jpg&fm=jpg'\n",
        "img = Image.open(requests.get(url, stream=True).raw)\n",
        "\n",
        "rgb_image = asarray(img)\n",
        "gray_image = np.average(rgb_image, axis=2, weights=[0.2989, 0.5870, 0.1140])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gg-gD3dOHmy8"
      },
      "outputs": [],
      "source": [
        "plt.imshow(gray_image, cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-c5EEKs9Hmy9"
      },
      "outputs": [],
      "source": [
        "def show_images(im,k):\n",
        "  start_time = time.time()\n",
        "  U, s, Vh = linalg.svd(im)\n",
        "  image1 = U[:, :k] @ np.diag(s[:k]) @ Vh[:k, :]\n",
        "  t1 = time.time()-start_time\n",
        "  start_time = time.time()\n",
        "  U, s, Vh = rsvd(im,k,0,10,4)\n",
        "  image2 = U @ np.diag(s) @ Vh\n",
        "  t2 = time.time()-start_time\n",
        "  start_time = time.time()\n",
        "  U, s, Vh = nrsvd(im,k,0,10,4)\n",
        "  image3 = U @ np.diag(s) @ Vh\n",
        "  t3 = time.time()-start_time\n",
        "  start_time = time.time()\n",
        "  U, s, Vh = srsvd(im,k,0,10,4)\n",
        "  image4 = U @ np.diag(s) @ Vh\n",
        "  t4 = time.time()-start_time\n",
        "\n",
        "  fig, axes = plt.subplots(nrows=2, ncols=2)\n",
        "\n",
        "  axes[0, 0].imshow(image1, cmap='gray')\n",
        "  axes[0, 0].set_title(f'svd, t = {t1:.2f}s')\n",
        "  axes[0, 0].axis('off')\n",
        "  axes[0, 1].imshow(image2, cmap='gray')\n",
        "  axes[0, 1].set_title(f'rsvd, t = {t2:.2f}s')\n",
        "  axes[0, 1].axis('off')\n",
        "  axes[1, 0].imshow(image3, cmap='gray')\n",
        "  axes[1, 0].set_title(f'nrsvd, t = {t3:.2f}s')\n",
        "  axes[1, 0].axis('off')\n",
        "  axes[1, 1].imshow(image4, cmap='gray')\n",
        "  axes[1, 1].set_title(f'srsvd, t = {t4:.2f}s')\n",
        "  axes[1, 1].axis('off')\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yeK_d12SHmy9"
      },
      "outputs": [],
      "source": [
        "show_images(gray_image,50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0s8ScobQny3"
      },
      "source": [
        "## Problem 3: PCA and its applications ``(50 pt.)``\n",
        "\n",
        "\n",
        "Principal Component Analysis (PCA) is a statistical technique commonly used in data analysis and machine learning for dimensionality reduction while preserving as much variance as possible. It helps in identifying patterns in data based on the correlation between features. The goal of PCA is to reduce the number of variables of a data set, while preserving as much information (variance) as possible.\n",
        "\n",
        "### Step 1: Standardize the Dataset\n",
        "Normalize each feature in the dataset to have zero mean and unit variance to ensure each feature contributes equally:\n",
        "\n",
        "\\begin{align}\n",
        "z_i = \\frac{(x_i - \\mu)}{\\sigma}\n",
        "\\end{align}\n",
        "\n",
        "### Step 2: Compute the Covariance Matrix\n",
        "Construct a covariance matrix to analyze how features vary from the mean with respect to each other, which helps in identifying correlated features:\n",
        "\n",
        "\\begin{align}\n",
        "C = \\frac{1}{n-1} \\times (X^T X)\n",
        "\\end{align}\n",
        "\n",
        "where \\( X \\) is the standardized data matrix.\n",
        "\n",
        "### Step 3: Calculate Eigenvalues and Eigenvectors\n",
        "Solve for eigenvalues and their corresponding eigenvectors of the covariance matrix; these will determine the new axes (principal components) for the data projection:\n",
        "\n",
        "\\begin{align}\n",
        "Cv = \\lambda v\n",
        "\\end{align}\n",
        "\n",
        "### Step 4: Sort Eigenvalues and Eigenvectors\n",
        "Order the eigenvalues from largest to smallest and rank the eigenvectors accordingly. This ranking indicates the relative significance of each principal component.\n",
        "\n",
        "### Step 5: Project Data onto Principal Components\n",
        "Transform the original dataset into a new coordinate system by projecting it onto the principal eigenvectors, reducing dimensionality while retaining most of the variance:\n",
        "\n",
        "\\begin{align}\n",
        "Y = XW\n",
        "\\end{align}\n",
        "\n",
        "Here, \\( W \\) is the matrix containing the selected eigenvectors, and \\( Y \\) is the transformed data matrix. This final transformation results in a new dataset that highlights the most significant relationships within the original data.\n",
        "\n",
        "---\n",
        "In the section below, import all the libraries you need:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zwe6LDJrRK8k"
      },
      "outputs": [],
      "source": [
        "# Code cell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqAuXAvARLuE"
      },
      "source": [
        "The MNIST dataset is a large collection of handwritten digits commonly used for training various image processing systems. It contains 70,000 images of handwritten digits from 0 to 9, each represented as a 28x28 pixel grayscale image.\n",
        "\n",
        "load the dataset and show the first 50 samples:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-EgoRmUR7vV"
      },
      "outputs": [],
      "source": [
        "#load the data set and fill nan value with 0\n",
        "from keras.datasets import mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Itvze8wTncX"
      },
      "outputs": [],
      "source": [
        "# here show 50 first of this images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jb0DfeXbT-eH"
      },
      "source": [
        "PCA is affected by scale, so you need to do some normalization on data before applying PCA.\n",
        "\n",
        "1- Reshape the data from a 28x28 matrix to a flattened 784-element vector.\n",
        "\n",
        "2- Subtract the mean and divide by the standard deviation for each sample.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I8QwKpJ2Xu2V"
      },
      "outputs": [],
      "source": [
        "# Code cell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IyWBUpM2X4g0"
      },
      "source": [
        "In this section, first obtain the covariance matrix of the data and then extract its eigenvalues and eigenvectors. Finally, sort the eigenvalues and their corresponding eigenvectors from largest to smallest."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9g3G-qNQYLHs"
      },
      "outputs": [],
      "source": [
        "# Code cell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQA6-jdqYfhU"
      },
      "source": [
        "Now, we want to examine how many components can represent 75 percent of the total variance of the data. Note that the variance of each component corresponds to its eigenvalue."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lGV5q6sbaEvW"
      },
      "outputs": [],
      "source": [
        "# Code cell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Twq8ae-waWUo"
      },
      "source": [
        "Now in this section, project the available data onto these components, perform dimensionality reduction, and then return the dimensions to the size of the original images. Draw an image of one of the samples for both states: before dimension reduction on the components and after it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X8D3_suqaXyG"
      },
      "outputs": [],
      "source": [
        "# Code cell"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsTZRZSBa94t"
      },
      "source": [
        "In this section, define a classifier such as SVM or RandomForest, and use the test and training data to determine the accuracy of the classifier. Repeat this process for different numbers of components and examine the impact of increasing the number of components on accuracy. Note that in this section, you can use built-in functions for performing PCA and classification. Additionally, identify which number of components results in the best accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DV3L3tfCYQV5"
      },
      "outputs": [],
      "source": [
        "# define a function that calculate PCA\n",
        "def do_pca(n_components, data):\n",
        "\n",
        "  pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1yRRssQYZ1E"
      },
      "outputs": [],
      "source": [
        "#define a function that gets the X data and Y labels and returns the accuracy of ml model.\n",
        "def ML_model(X, y, print_output=True):\n",
        "\n",
        "  pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jeDwlJQCYZnB"
      },
      "outputs": [],
      "source": [
        "#your code to plot the accuracy of projected train data on one ml model(choose on your own reggression , random forest , ...)\n",
        "#consider number of component from 2 to 101 and calculate accuracy based on number of components"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
